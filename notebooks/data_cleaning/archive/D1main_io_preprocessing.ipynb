{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook used to help create:\n",
    "\n",
    "- importing data src\n",
    "- precprocessing data src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\bjk1y13\\\\OneDrive - University of Southampton\\\\MH028_UHS_Weather\\\\4_Analysis\\\\EDclassification\\\\notebooks'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.data.io import import_pickled_feature_dfs, import_merge_prevday_target_column, import_merge_pickled_target_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = import_pickled_feature_dfs('../data/interim/', ['callender.pkl', 'EDmorn.pkl', 'EDprevday.pkl', 'IPocc_perc.pkl', 'IPmorn.pkl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = import_merge_prevday_target_column('../data/interim/', 'EDooc_class.pkl', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = import_merge_pickled_target_class('../data/interim/', 'EDooc_class.pkl', features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flag_target</th>\n",
       "      <th>EDoccMAX_prevday</th>\n",
       "      <th>callender_DAY(first_EDatt_time)</th>\n",
       "      <th>callender_MONTH(first_EDatt_time)</th>\n",
       "      <th>callender_YEAR(first_EDatt_time)</th>\n",
       "      <th>callender_WEEKEND(first_EDatt_time)</th>\n",
       "      <th>EDmorn_COUNT(EDatt)</th>\n",
       "      <th>EDmorn_MEAN(EDatt.wait_time_total)</th>\n",
       "      <th>EDmorn_MEAN(EDatt.flag_specreq)</th>\n",
       "      <th>EDmorn_MEAN(EDatt.age)</th>\n",
       "      <th>...</th>\n",
       "      <th>IPocc_perc</th>\n",
       "      <th>IP_admissions_elec_nonelec</th>\n",
       "      <th>IP_discharges_elec_nonelec_PRE12</th>\n",
       "      <th>IPmorn_count</th>\n",
       "      <th>IPmorn_count_elec</th>\n",
       "      <th>IPmorn_count_nonelec</th>\n",
       "      <th>IPmorn_age_mean</th>\n",
       "      <th>IPmorn_age_std</th>\n",
       "      <th>IPmorn_age_skew</th>\n",
       "      <th>IPmorn_prop_nonelec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>43.583333</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>104.916667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.745533</td>\n",
       "      <td>122.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>955.0</td>\n",
       "      <td>65.192703</td>\n",
       "      <td>24.748781</td>\n",
       "      <td>-1.113181</td>\n",
       "      <td>0.893358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-03</th>\n",
       "      <td>0</td>\n",
       "      <td>45.250000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>32</td>\n",
       "      <td>157.272727</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>50.781250</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857756</td>\n",
       "      <td>210.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1137.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>64.325418</td>\n",
       "      <td>24.896858</td>\n",
       "      <td>-1.067481</td>\n",
       "      <td>0.853122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-04</th>\n",
       "      <td>0</td>\n",
       "      <td>50.708333</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>31</td>\n",
       "      <td>176.916667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>36.645161</td>\n",
       "      <td>...</td>\n",
       "      <td>0.909221</td>\n",
       "      <td>181.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1141.0</td>\n",
       "      <td>156.0</td>\n",
       "      <td>973.0</td>\n",
       "      <td>62.812445</td>\n",
       "      <td>25.652021</td>\n",
       "      <td>-0.942528</td>\n",
       "      <td>0.852761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-05</th>\n",
       "      <td>0</td>\n",
       "      <td>38.666667</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>True</td>\n",
       "      <td>30</td>\n",
       "      <td>160.217391</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>39.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.897069</td>\n",
       "      <td>149.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>936.0</td>\n",
       "      <td>62.668478</td>\n",
       "      <td>25.448019</td>\n",
       "      <td>-0.917823</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-01-06</th>\n",
       "      <td>0</td>\n",
       "      <td>42.250000</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>True</td>\n",
       "      <td>41</td>\n",
       "      <td>171.045455</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>46.682927</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819871</td>\n",
       "      <td>136.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1121.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>62.371097</td>\n",
       "      <td>25.658430</td>\n",
       "      <td>-0.900726</td>\n",
       "      <td>0.869759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            flag_target  EDoccMAX_prevday  callender_DAY(first_EDatt_time)  \\\n",
       "2013-01-02            0         43.583333                                2   \n",
       "2013-01-03            0         45.250000                                3   \n",
       "2013-01-04            0         50.708333                                4   \n",
       "2013-01-05            0         38.666667                                5   \n",
       "2013-01-06            0         42.250000                                6   \n",
       "\n",
       "            callender_MONTH(first_EDatt_time)  \\\n",
       "2013-01-02                                  1   \n",
       "2013-01-03                                  1   \n",
       "2013-01-04                                  1   \n",
       "2013-01-05                                  1   \n",
       "2013-01-06                                  1   \n",
       "\n",
       "            callender_YEAR(first_EDatt_time)  \\\n",
       "2013-01-02                              2013   \n",
       "2013-01-03                              2013   \n",
       "2013-01-04                              2013   \n",
       "2013-01-05                              2013   \n",
       "2013-01-06                              2013   \n",
       "\n",
       "            callender_WEEKEND(first_EDatt_time)  EDmorn_COUNT(EDatt)  \\\n",
       "2013-01-02                                False                   24   \n",
       "2013-01-03                                False                   32   \n",
       "2013-01-04                                False                   31   \n",
       "2013-01-05                                 True                   30   \n",
       "2013-01-06                                 True                   41   \n",
       "\n",
       "            EDmorn_MEAN(EDatt.wait_time_total)  \\\n",
       "2013-01-02                          104.916667   \n",
       "2013-01-03                          157.272727   \n",
       "2013-01-04                          176.916667   \n",
       "2013-01-05                          160.217391   \n",
       "2013-01-06                          171.045455   \n",
       "\n",
       "            EDmorn_MEAN(EDatt.flag_specreq)  EDmorn_MEAN(EDatt.age)  ...  \\\n",
       "2013-01-02                         0.833333               45.250000  ...   \n",
       "2013-01-03                         0.727273               50.781250  ...   \n",
       "2013-01-04                         0.666667               36.645161  ...   \n",
       "2013-01-05                         0.695652               39.866667  ...   \n",
       "2013-01-06                         0.590909               46.682927  ...   \n",
       "\n",
       "            IPocc_perc  IP_admissions_elec_nonelec  \\\n",
       "2013-01-02    0.745533                       122.0   \n",
       "2013-01-03    0.857756                       210.0   \n",
       "2013-01-04    0.909221                       181.0   \n",
       "2013-01-05    0.897069                       149.0   \n",
       "2013-01-06    0.819871                       136.0   \n",
       "\n",
       "            IP_discharges_elec_nonelec_PRE12  IPmorn_count  IPmorn_count_elec  \\\n",
       "2013-01-02                              39.0        1069.0               97.0   \n",
       "2013-01-03                              39.0        1137.0              151.0   \n",
       "2013-01-04                              70.0        1141.0              156.0   \n",
       "2013-01-05                              50.0        1104.0              150.0   \n",
       "2013-01-06                              36.0        1121.0              136.0   \n",
       "\n",
       "            IPmorn_count_nonelec  IPmorn_age_mean  IPmorn_age_std  \\\n",
       "2013-01-02                 955.0        65.192703       24.748781   \n",
       "2013-01-03                 970.0        64.325418       24.896858   \n",
       "2013-01-04                 973.0        62.812445       25.652021   \n",
       "2013-01-05                 936.0        62.668478       25.448019   \n",
       "2013-01-06                 975.0        62.371097       25.658430   \n",
       "\n",
       "            IPmorn_age_skew  IPmorn_prop_nonelec  \n",
       "2013-01-02        -1.113181             0.893358  \n",
       "2013-01-03        -1.067481             0.853122  \n",
       "2013-01-04        -0.942528             0.852761  \n",
       "2013-01-05        -0.917823             0.847826  \n",
       "2013-01-06        -0.900726             0.869759  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1713\n",
       "1     306\n",
       "Name: flag_target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.flag_target.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "\n",
    "#### split test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocess import make_timeseries_test_train_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA POINTS:\n",
      "orig size 2019\n",
      "training:  1654\n",
      "testing:  365\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = make_timeseries_test_train_splits(features, 'flag_target', 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocess import get_variable_types_lists, check_for_catagorical_type_difference_between_train_test, change_feature_types_to_numeric\n",
    "    \n",
    "\n",
    "num_features, cat_features, bin_features = get_variable_types_lists(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find problem columns that will crash preprocessing pipleine when converting test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature name:  callender_YEAR(first_EDatt_time)\n",
      "Categories in training:  {2016, 2017, 2013, 2014, 2015}\n",
      "Categories in testing:  {2017, 2018}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "problem_col_list = check_for_catagorical_type_difference_between_train_test(X_train, X_test, cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treat problem features as numerical so that process can continue.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features, num_features = change_feature_types_to_numeric(problem_col_list, cat_features, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use sklearn pipelines to clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 19.2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from src.data.preprocess import DataFrameSelector, MakeBooleanAnInteger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col_name in cat_features:\n",
    "    values_list = X_train[col_name].unique()\n",
    "    for value in values_list:\n",
    "        print(col_name + '_' + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### failed to get this to work as kept doubling size of output array. Didnt matter if get_col_list_for_after_pipeline fundtion was inside or outside of DataFrameReform class.\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameReform(BaseEstimator,TransformerMixin):\n",
    "    \" Takes numpy array and forms into dataframe with column names.\"\n",
    "    def __init__(self, new_features_list):\n",
    "        self.new_features_list = new_features_list\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):        \n",
    "        return(pd.DataFrame(X, columns = self.new_features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\envs\\class\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(num_features)),\n",
    "    ('feature_filter',SelectKBest(f_classif,k='all')),\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('std_scaler',StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(cat_features)),\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('OneHot_encoder',OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "bin_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(bin_features)),\n",
    "    ('boolean_conversion',MakeBooleanAnInteger()),\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    #('encoding',LabelEncoder()),\n",
    "])\n",
    "\n",
    "df_reform_pipeline = Pipeline([\n",
    "    ('reform_df', DataFrameReform(new_features_list))\n",
    "])\n",
    "\n",
    "#### create list of pipelines to include\n",
    "\n",
    "pipes_list = [\n",
    "    ('num_pipeline',num_pipeline),\n",
    "  ('cat_pipeline',cat_pipeline),\n",
    "  ('bin_pipeline',bin_pipeline),\n",
    "#     ('df_reform_pipeline', df_reform_pipeline)\n",
    "]\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=pipes_list\n",
    ")\n",
    "\n",
    "\n",
    "X_trainT = full_pipeline.fit_transform(X_train,y_train)\n",
    "X_testT = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1654, 41)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1654, 52)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_list_for_after_pipeline(X, num_features, cat_features, bin_features):\n",
    "    cat_features_new = []\n",
    "    #### get new names for cat_features - must do here, otherwise when call fit transform the cat_features_new is appedned too twice.\n",
    "#     print('TRANSFORM METHOD')\n",
    "    for col_name in cat_features:\n",
    "#         print('CAT FEATURES LOOP', col_name)\n",
    "        values_list = X[col_name].unique()\n",
    "        for value in values_list:\n",
    "            cat_features_new.append(col_name + '_' + str(value))\n",
    "#         print(cat_features_new)\n",
    "    \n",
    "    columns_list = num_features + cat_features_new + bin_features\n",
    "#     print(len(columns_list))\n",
    "    return(columns_list)\n",
    "\n",
    "new_features_list = get_col_list_for_after_pipeline(X_train, num_features, cat_features, bin_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reform_df(X, new_features_list):\n",
    "    return(pd.DataFrame(X, columns= new_features_list))\n",
    "\n",
    "X_trainT = reform_df(X_trainT, new_features_list)\n",
    "X_testT = reform_df(X_testT, new_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 52)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1654, 52)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 52)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save preprocessed out as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle_preprocessed_data(path, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Take prepared data which has been split into Train/Test and has been scaled/blanks filled/...., and save to pickle files at specified location.\n",
    "    \n",
    "    Input\n",
    "    =====\n",
    "    path, str, to folder where data should be saved. Must end in /\n",
    "\n",
    "    X_train/X_test/y_train,/y_test, dataframes, conatining data.\n",
    "    \n",
    "    Ouput\n",
    "    =====\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #### create folder with versioned name etc.(future dev)\n",
    "    \n",
    "    pd.to_pickle(X_train, path + 'X_train.pkl')\n",
    "    pd.to_pickle(X_test, path + 'X_test.pkl')\n",
    "    pd.to_pickle(y_train, path + 'y_train.pkl')\n",
    "    pd.to_pickle(y_test, path + 'y_test.pkl')\n",
    "    \n",
    "    return\n",
    "\n",
    "save_pickle_preprocessed_data('../data/processed/v1/', X_trainT, X_testT, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: consider creating log for preprocessing information in order for repeatability in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:EDclass]",
   "language": "python",
   "name": "conda-env-EDclass-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
