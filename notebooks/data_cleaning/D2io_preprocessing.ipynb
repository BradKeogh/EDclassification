{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook used to help create:\n",
    "\n",
    "- importing data src\n",
    "- precprocessing data src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.data.io import import_pickled_feature_dfs, import_merge_prevday_target_column, import_merge_pickled_target_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = import_pickled_feature_dfs('../../data/interim/D2_timeseries/', ['EDsummary.pkl', 'callender.pkl'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2465, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = pd.read_pickle('../../data/interim/EDooc_class.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = target.merge(features, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remeber to OFFSET target!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_final = features.copy()\n",
    "features_final['flag_target'] = features_final['flag_target'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    2094\n",
       "1.0     370\n",
       "Name: flag_target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_final.flag_target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EDocc</th>\n",
       "      <th>flag_target</th>\n",
       "      <th>attendances</th>\n",
       "      <th>admissions</th>\n",
       "      <th>age_mean</th>\n",
       "      <th>age_65plus</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dt_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-09-26</th>\n",
       "      <td>59.791667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>487</td>\n",
       "      <td>188</td>\n",
       "      <td>44.7064</td>\n",
       "      <td>134</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-27</th>\n",
       "      <td>63.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>482</td>\n",
       "      <td>168</td>\n",
       "      <td>44.1992</td>\n",
       "      <td>126</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-28</th>\n",
       "      <td>56.541667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>463</td>\n",
       "      <td>191</td>\n",
       "      <td>46.4989</td>\n",
       "      <td>138</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-29</th>\n",
       "      <td>44.125000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>367</td>\n",
       "      <td>157</td>\n",
       "      <td>40.3597</td>\n",
       "      <td>79</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-30</th>\n",
       "      <td>55.541667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>454</td>\n",
       "      <td>174</td>\n",
       "      <td>41.5308</td>\n",
       "      <td>110</td>\n",
       "      <td>2018</td>\n",
       "      <td>9</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                EDocc  flag_target attendances admissions age_mean age_65plus  \\\n",
       "dt_date                                                                         \n",
       "2018-09-26  59.791667          1.0         487        188  44.7064        134   \n",
       "2018-09-27  63.250000          0.0         482        168  44.1992        126   \n",
       "2018-09-28  56.541667          0.0         463        191  46.4989        138   \n",
       "2018-09-29  44.125000          0.0         367        157  40.3597         79   \n",
       "2018-09-30  55.541667          NaN         454        174  41.5308        110   \n",
       "\n",
       "            year  month  dayofweek  \n",
       "dt_date                             \n",
       "2018-09-26  2018      9  Wednesday  \n",
       "2018-09-27  2018      9   Thursday  \n",
       "2018-09-28  2018      9     Friday  \n",
       "2018-09-29  2018      9   Saturday  \n",
       "2018-09-30  2018      9     Sunday  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_final.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing\n",
    "\n",
    "#### split test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocess import make_timeseries_test_train_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA POINTS:\n",
      "orig size 2465\n",
      "training:  2100\n",
      "testing:  365\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = make_timeseries_test_train_splits(features_final, 'flag_target', 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.preprocess import get_variable_types_lists, check_for_catagorical_type_difference_between_train_test, change_feature_types_to_numeric\n",
    "    \n",
    "\n",
    "# num_features, cat_features, bin_features = get_variable_types_lists(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EDocc', 'attendances', 'admissions', 'age_mean', 'age_65plus', 'year',\n",
       "       'month', 'dayofweek'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['month','dayofweek']\n",
    "num_features = list(set(X_train.columns) - set(cat_features))\n",
    "bin_features = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find problem columns that will crash preprocessing pipleine when converting test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem_col_list = check_for_catagorical_type_difference_between_train_test(X_train, X_test, cat_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treat problem features as numerical so that process can continue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use sklearn pipelines to clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# version 19.2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "from src.data.preprocess import DataFrameSelector, MakeBooleanAnInteger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col_name in cat_features:\n",
    "    values_list = X_train[col_name].unique()\n",
    "    for value in values_list:\n",
    "        print(col_name + '_' + str(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### failed to get this to work as kept doubling size of output array. Didnt matter if get_col_list_for_after_pipeline fundtion was inside or outside of DataFrameReform class.\n",
    "\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DataFrameReform(BaseEstimator,TransformerMixin):\n",
    "    \" Takes numpy array and forms into dataframe with column names.\"\n",
    "    def __init__(self, new_features_list):\n",
    "        self.new_features_list = new_features_list\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self,X):        \n",
    "        return(pd.DataFrame(X, columns = self.new_features_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(num_features)),\n",
    "    ('feature_filter',SelectKBest(f_classif,k='all')),\n",
    "    ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('std_scaler',StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(cat_features)),\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('OneHot_encoder',OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "bin_pipeline = Pipeline([\n",
    "    ('selector',DataFrameSelector(bin_features)),\n",
    "    ('boolean_conversion',MakeBooleanAnInteger()),\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    #('encoding',LabelEncoder()),\n",
    "])\n",
    "\n",
    "# df_reform_pipeline = Pipeline([\n",
    "#     ('reform_df', DataFrameReform(new_features_list))\n",
    "# ])\n",
    "\n",
    "#### create list of pipelines to include\n",
    "\n",
    "pipes_list = [\n",
    "    ('num_pipeline',num_pipeline),\n",
    "  ('cat_pipeline',cat_pipeline),\n",
    "#   ('bin_pipeline',bin_pipeline),\n",
    "#     ('df_reform_pipeline', df_reform_pipeline)\n",
    "]\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=pipes_list\n",
    ")\n",
    "\n",
    "\n",
    "X_trainT = full_pipeline.fit_transform(X_train,y_train)\n",
    "X_testT = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 25)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_list_for_after_pipeline(X, num_features, cat_features, bin_features):\n",
    "    cat_features_new = []\n",
    "    #### get new names for cat_features - must do here, otherwise when call fit transform the cat_features_new is appedned too twice.\n",
    "#     print('TRANSFORM METHOD')\n",
    "    for col_name in cat_features:\n",
    "#         print('CAT FEATURES LOOP', col_name)\n",
    "        values_list = X[col_name].unique()\n",
    "        for value in values_list:\n",
    "            cat_features_new.append(col_name + '_' + str(value))\n",
    "#         print(cat_features_new)\n",
    "    \n",
    "    columns_list = num_features + cat_features_new + bin_features\n",
    "#     print(len(columns_list))\n",
    "    return(columns_list)\n",
    "\n",
    "new_features_list = get_col_list_for_after_pipeline(X_train, num_features, cat_features, bin_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reform_df(X, new_features_list):\n",
    "    return(pd.DataFrame(X, columns= new_features_list))\n",
    "\n",
    "X_trainT = reform_df(X_trainT, new_features_list)\n",
    "X_testT = reform_df(X_testT, new_features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 25)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2100, 25)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_trainT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 25)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_testT.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save preprocessed out as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle_preprocessed_data(path, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    Take prepared data which has been split into Train/Test and has been scaled/blanks filled/...., and save to pickle files at specified location.\n",
    "    \n",
    "    Input\n",
    "    =====\n",
    "    path, str, to folder where data should be saved. Must end in /\n",
    "\n",
    "    X_train/X_test/y_train,/y_test, dataframes, conatining data.\n",
    "    \n",
    "    Ouput\n",
    "    =====\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #### create folder with versioned name etc.(future dev)\n",
    "    \n",
    "    pd.to_pickle(X_train, path + 'X_train.pkl')\n",
    "    pd.to_pickle(X_test, path + 'X_test.pkl')\n",
    "    pd.to_pickle(y_train, path + 'y_train.pkl')\n",
    "    pd.to_pickle(y_test, path + 'y_test.pkl')\n",
    "    \n",
    "    return\n",
    "\n",
    "save_pickle_preprocessed_data('../../data/processed/D2/', X_trainT, X_testT, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: consider creating log for preprocessing information in order for repeatability in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:class]",
   "language": "python",
   "name": "conda-env-class-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
