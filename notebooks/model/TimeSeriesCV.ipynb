{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(max_train_size=None, n_splits=5)\n",
      "TRAIN: [0] TEST: [1]\n",
      "TRAIN: [0 1] TEST: [2]\n",
      "TRAIN: [0 1 2] TEST: [3]\n",
      "TRAIN: [0 1 2 3] TEST: [4]\n",
      "TRAIN: [0 1 2 3 4] TEST: [5]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "y = np.array([1, 2, 3, 4, 5, 6])\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "print(tscv)  \n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "   X_train, X_test = X[train_index], X[test_index]\n",
    "   y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeSeriesSplit(max_train_size=1, n_splits=3)\n",
      "TRAIN: [2] TEST: [3]\n",
      "TRAIN: [3] TEST: [4]\n",
      "TRAIN: [4] TEST: [5]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=3,max_train_size=1)\n",
    "print(tscv)  \n",
    "\n",
    "for train_index, test_index in tscv.split(X):\n",
    "   print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "   X_train, X_test = X[train_index], X[test_index]\n",
    "   y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### edit sklearn class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_BaseKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-ad5e8069cb67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mTimeSeriesSplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_BaseKFold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \"\"\"Time Series cross-validator\n\u001b[0;32m      3\u001b[0m     \u001b[0mProvides\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0mindices\u001b[0m \u001b[0mto\u001b[0m \u001b[0msplit\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mseries\u001b[0m \u001b[0mdata\u001b[0m \u001b[0msamples\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mthat\u001b[0m \u001b[0mare\u001b[0m \u001b[0mobserved\u001b[0m \u001b[0mat\u001b[0m \u001b[0mfixed\u001b[0m \u001b[0mtime\u001b[0m \u001b[0mintervals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtest\u001b[0m \u001b[0msets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mIn\u001b[0m \u001b[0meach\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0mindices\u001b[0m \u001b[0mmust\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mhigher\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mbefore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mthus\u001b[0m \u001b[0mshuffling\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name '_BaseKFold' is not defined"
     ]
    }
   ],
   "source": [
    "class TimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals, in train/test sets.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=3\n",
    "        Number of splits. Must be at least 2.\n",
    "        .. versionchanged:: 0.20\n",
    "            ``n_splits`` default value will change from 3 to 5 in v0.22.\n",
    "    max_train_size : int, optional\n",
    "        Maximum size for a single training set.\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> from sklearn.model_selection import TimeSeriesSplit\n",
    "    >>> X = np.array([[1, 2], [3, 4], [1, 2], [3, 4], [1, 2], [3, 4]])\n",
    "    >>> y = np.array([1, 2, 3, 4, 5, 6])\n",
    "    >>> tscv = TimeSeriesSplit(n_splits=5)\n",
    "    >>> print(tscv)  # doctest: +NORMALIZE_WHITESPACE\n",
    "    TimeSeriesSplit(max_train_size=None, n_splits=5)\n",
    "    >>> for train_index, test_index in tscv.split(X):\n",
    "    ...    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    ...    X_train, X_test = X[train_index], X[test_index]\n",
    "    ...    y_train, y_test = y[train_index], y[test_index]\n",
    "    TRAIN: [0] TEST: [1]\n",
    "    TRAIN: [0 1] TEST: [2]\n",
    "    TRAIN: [0 1 2] TEST: [3]\n",
    "    TRAIN: [0 1 2 3] TEST: [4]\n",
    "    TRAIN: [0 1 2 3 4] TEST: [5]\n",
    "    Notes\n",
    "    -----\n",
    "    The training set has size ``i * n_samples // (n_splits + 1)\n",
    "    + n_samples % (n_splits + 1)`` in the ``i``th split,\n",
    "    with a test set of size ``n_samples//(n_splits + 1)``,\n",
    "    where ``n_samples`` is the number of samples.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_splits='warn', max_train_size=None):\n",
    "        if n_splits == 'warn':\n",
    "            warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
    "            n_splits = 3\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_size = max_train_size\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like, shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like, with shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        n_folds = n_splits + 1\n",
    "        if n_folds > n_samples:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds ={0} greater\"\n",
    "                 \" than the number of samples: {1}.\").format(n_folds,\n",
    "                                                             n_samples))\n",
    "        indices = np.arange(n_samples)\n",
    "        test_size = (n_samples // n_folds)\n",
    "        test_starts = range(test_size + n_samples % n_folds,\n",
    "                            n_samples, test_size)\n",
    "        for test_start in test_starts:\n",
    "            if self.max_train_size and self.max_train_size < test_start:\n",
    "                yield (indices[test_start - self.max_train_size:test_start],\n",
    "                       indices[test_start:test_start + test_size])\n",
    "            else:\n",
    "                yield (indices[:test_start],\n",
    "                       indices[test_start:test_start + test_size])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
